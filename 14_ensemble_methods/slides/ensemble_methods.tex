\input{../../_common/preamble}

\title{Ensemble methods}

\begin{document}

\maketitle

\begin{frame}{Ensemble methods}
    \begin{block}{Idea}
        \begin{itemize}
            \item Train a \alert{set} of learners
            \item Combine their predictions
        \end{itemize}
    \end{block}
    \vfill
    \begin{block}{Motivation}
        \begin{itemize}
            \item More flexible $\rightarrow$ reduce bias
            \item Less prone to overfitting $\rightarrow$ reduce variance
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Why do ensembles work?}
    Assume 10 classifiers\ldots
    \begin{itemize}
        \item Each with error rate $\epsilon$ = 30\%
        \item Independent (not feasible in practice!)
    \end{itemize}
    \vfill
    What's the probability that the ensemble makes a wrong prediction?
    \pause
    \begin{itemize}
        \item Wrong prediction $\rightarrow$ majority ($\geq$ 6) makes a wrong
              prediction
        \item The probability is given by the binomial distribution,
              \[
                  \sum_{k = 6}^{10} \binom{10}{k} \epsilon^{k} (1 - \epsilon)^{10 - k} \approx 4.73\% \ll \epsilon
              \]
    \end{itemize}
\end{frame}

\begin{frame}{Contents}
    \tableofcontents[hideallsubsections]
\end{frame}

\section{Bagging}

\begin{frame}{Bagging (bootstrap aggregating)}
    \only<1>{%
        \begin{itemize}
            \item Multiple datasets generated by \alert{sampling with replacement}
            \item The probability that a given observation is \emph{not} selected is
                  \[
                      \left( 1 - \frac{1}{n} \right)^{n}
                  \]
            \item For large $n$, we have
                  \[
                      \lim_{n \to +\infty} \left( 1 - \frac{1}{n} \right)^{n} = \frac{1}{e} \approx 36.79\%
                  \]
            \item[$\rightarrow$] Each dataset contains slightly less than 2/3 of the observations
        \end{itemize}}
    \only<2>{%
        \begin{block}{Variations}
            \begin{itemize}
                \item Different types of learners
                \item Sampling of variables
                \item Sampling without replacement
                \item Size of subset
            \end{itemize}
        \end{block}}
\end{frame}

\section{Boosting}

\begin{frame}{Boosting}
    \only<1>{%
        \begin{block}{Idea}
            \begin{itemize}
                \item `Later' learners focus on observations that were predicted
                      incorrectly by `earlier' learners
                \item Aggregation is weighted by errors
            \end{itemize}
        \end{block}
        \vfill
        \begin{block}{Implementation}
            \begin{itemize}
                \item Iterative procedure with weight updates
                \item \alert{Increase} the weight of
                      \alert{incorrectly classified} observations
            \end{itemize}
        \end{block}}
    \only<2>{%
        Compared to bagging, boosting is\ldots
        \begin{itemize}
            \item Much less noise\hyp{}tolerant
            \item More accurate (if it works)
            \item Less well\hyp{}calibrated
        \end{itemize}}
\end{frame}

\section{Stacking}

\begin{frame}{Stacking}
    \begin{block}{Idea}
        \begin{itemize}
            \item Use a learner to combine predictions from multiple learners
            \item Trained using:
                  \begin{description}
                      \item[$\mat{X}$] Cross\hyp{}validated predictions
                      \item[$\vec{y}$] Class labels of training data
                  \end{description}
        \end{itemize}
    \end{block}
    \vfill
    \begin{block}{Meta\hyp{}learners}
        \begin{itemize}
            \item Not restricted to being linear (as in voting)
            \item Should learn how the (base) learners make mistakes
        \end{itemize}
    \end{block}
\end{frame}

\end{document}

